{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb4d600",
   "metadata": {},
   "source": [
    "## Scraping non-tabular, multipage sites\n",
    "Scrape the top 500 <a href=\"https://bestsellingalbums.org/decade/2010\">best-selling albums of the 2010's</a>. Your data must include the following datapoints:\n",
    "\n",
    "- Name of album\n",
    "- Name of artist\n",
    "- Number of albums sold \n",
    "- The link to the page that breaks down sales by country (found by clicking album title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca905d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create cells as needed\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randrange\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd3b07-2c1a-4427-b6cf-9b0d4d5bcc47",
   "metadata": {},
   "source": [
    "### Scraping pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8ed827-5e04-48b8-9b23-314d663dd5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1 of 10...\n",
      "Snoozing for 10 seconds before moving on to the next page.\n",
      "Scraping page 2 of 10...\n",
      "Snoozing for 8 seconds before moving on to the next page.\n",
      "Scraping page 3 of 10...\n",
      "Snoozing for 6 seconds before moving on to the next page.\n",
      "Scraping page 4 of 10...\n",
      "Snoozing for 8 seconds before moving on to the next page.\n",
      "Scraping page 5 of 10...\n",
      "Snoozing for 11 seconds before moving on to the next page.\n",
      "Scraping page 6 of 10...\n",
      "Snoozing for 7 seconds before moving on to the next page.\n",
      "Scraping page 7 of 10...\n",
      "Snoozing for 9 seconds before moving on to the next page.\n",
      "Scraping page 8 of 10...\n",
      "Snoozing for 6 seconds before moving on to the next page.\n",
      "Scraping page 9 of 10...\n",
      "Snoozing for 7 seconds before moving on to the next page.\n",
      "Scraping page 10 of 10...\n",
      "Snoozing for 5 seconds before moving on to the next page.\n",
      "Scraping is done!\n"
     ]
    }
   ],
   "source": [
    "# top 500 best-selling albums\n",
    "# there are 50 items per page\n",
    "\n",
    "base_url = \"https://bestsellingalbums.org/decade/2010-\" # includes a hyphen at the end \n",
    "last_page = 10 # total number of pages we have to scrape\n",
    "\n",
    "errors_list = []\n",
    "albums_list = []\n",
    "artists_list = []\n",
    "sales_list = []\n",
    "links_list = []\n",
    "\n",
    "def page_scraper(url):\n",
    "    # setting up soup\n",
    "    if response.status_code == 200:\n",
    "        # scraping albums\n",
    "        albums = albums_list.extend([ album.get_text() for album in soup.find_all(\"div\", class_=\"album\") ])\n",
    "        # scraping artists\n",
    "        artists = artists_list.extend([ artist.get_text() for artist in soup.find_all(\"div\", class_=\"artist\") ])\n",
    "        # scraping albums sold\n",
    "        sales = sales_list.extend([ int(sale.get_text().replace(\"Sales: \", \"\").replace(\",\", \"\")) for sale in soup.find_all(\"div\", class_=\"sales\") ])\n",
    "        # scraping link to sales breakdown\n",
    "        links = links_list.extend([ s[\"href\"] for s in soup.select(\"div.album > a[href]\") ])\n",
    "    else:\n",
    "        print(\"Failed to scrape\")\n",
    "\n",
    "    return albums, artists, sales, links\n",
    "\n",
    "for page_num in range(1, last_page +1): # +1 to make sure I get the last page\n",
    "    if page_num == 1: # \"-0\" and \"-1\" lead to an error! so we're scraping the first page differently...\n",
    "        print(f\"Scraping page {page_num} of {last_page}...\")\n",
    "        url = base_url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        albums, artists, sales, links = page_scraper(url)  \n",
    "        snoozer = randrange(5, 12)\n",
    "        print(f\"Snoozing for {snoozer} seconds before moving on to the next page.\")\n",
    "        time.sleep(snoozer)\n",
    "    else:\n",
    "        print(f\"Scraping page {page_num} of {last_page}...\")\n",
    "        url = f\"{base_url}{page_num}\"  # this starts at page 2...\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        try:\n",
    "            albums, artists, sales, links = page_scraper(url)  \n",
    "        except Exception as e:\n",
    "            errors_list.append(page_num, e)\n",
    "            print(f\"Something went wrong in page {page_num} due to {e}.\")\n",
    "        finally:\n",
    "            snoozer = randrange(5, 12)\n",
    "            print(f\"Snoozing for {snoozer} seconds before moving on to the next page.\")\n",
    "            time.sleep(snoozer)\n",
    "\n",
    "print(\"Scraping is done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfaa21c-7a91-4c7d-b3fa-87ee15bf06b9",
   "metadata": {},
   "source": [
    "### Saving to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08dd1fc4-8f4f-4b2c-ade0-de5508eb2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2010_albums = list(zip(albums_list, artists_list, sales_list, links_list))\n",
    "main_df = pd.DataFrame(df_2010_albums, columns=[\"Album\", \"Artist\", \"Total Sales\", \"Link to Country Sales Breakdown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73115e69-aa21-4711-9101-d9094e938319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Album</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Total Sales</th>\n",
       "      <th>Link to Country Sales Breakdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>ADELE</td>\n",
       "      <td>30000000</td>\n",
       "      <td>https://bestsellingalbums.org/album/1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>ADELE</td>\n",
       "      <td>23000000</td>\n",
       "      <td>https://bestsellingalbums.org/album/1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHRISTMAS</td>\n",
       "      <td>MICHAEL BUBLÉ</td>\n",
       "      <td>15000000</td>\n",
       "      <td>https://bestsellingalbums.org/album/30524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989</td>\n",
       "      <td>TAYLOR SWIFT</td>\n",
       "      <td>14748116</td>\n",
       "      <td>https://bestsellingalbums.org/album/45488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PURPOSE</td>\n",
       "      <td>JUSTIN BIEBER</td>\n",
       "      <td>14000000</td>\n",
       "      <td>https://bestsellingalbums.org/album/23318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>UNDER PRESSURE</td>\n",
       "      <td>LOGIC</td>\n",
       "      <td>1060000</td>\n",
       "      <td>https://bestsellingalbums.org/album/27268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>THE STRANGE CASE OF</td>\n",
       "      <td>HALESTORM</td>\n",
       "      <td>1060000</td>\n",
       "      <td>https://bestsellingalbums.org/album/17960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>UNCAGED</td>\n",
       "      <td>ZAC BROWN BAND</td>\n",
       "      <td>1055000</td>\n",
       "      <td>https://bestsellingalbums.org/album/56701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>FUTURE</td>\n",
       "      <td>FUTURE</td>\n",
       "      <td>1050371</td>\n",
       "      <td>https://bestsellingalbums.org/album/16036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>HNDRXX</td>\n",
       "      <td>FUTURE</td>\n",
       "      <td>1050000</td>\n",
       "      <td>https://bestsellingalbums.org/album/16039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Album          Artist  Total Sales  \\\n",
       "0                     21           ADELE     30000000   \n",
       "1                     25           ADELE     23000000   \n",
       "2              CHRISTMAS   MICHAEL BUBLÉ     15000000   \n",
       "3                   1989    TAYLOR SWIFT     14748116   \n",
       "4                PURPOSE   JUSTIN BIEBER     14000000   \n",
       "..                   ...             ...          ...   \n",
       "495       UNDER PRESSURE           LOGIC      1060000   \n",
       "496  THE STRANGE CASE OF       HALESTORM      1060000   \n",
       "497              UNCAGED  ZAC BROWN BAND      1055000   \n",
       "498               FUTURE          FUTURE      1050371   \n",
       "499               HNDRXX          FUTURE      1050000   \n",
       "\n",
       "               Link to Country Sales Breakdown  \n",
       "0     https://bestsellingalbums.org/album/1034  \n",
       "1     https://bestsellingalbums.org/album/1035  \n",
       "2    https://bestsellingalbums.org/album/30524  \n",
       "3    https://bestsellingalbums.org/album/45488  \n",
       "4    https://bestsellingalbums.org/album/23318  \n",
       "..                                         ...  \n",
       "495  https://bestsellingalbums.org/album/27268  \n",
       "496  https://bestsellingalbums.org/album/17960  \n",
       "497  https://bestsellingalbums.org/album/56701  \n",
       "498  https://bestsellingalbums.org/album/16036  \n",
       "499  https://bestsellingalbums.org/album/16039  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b774df2-4e93-4b35-99ea-fbe30d42e93e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
